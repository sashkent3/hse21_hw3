{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rFZS5A_yy1o"
   },
   "source": [
    "# Подготовка файлов и программ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DFpK_Pf1hAX"
   },
   "source": [
    "## Установка HISAT2 (для выравниваия RNA-seq чтений на геном)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-Eyz3aD3m8-",
    "outputId": "6638a47a-50bf-4a3b-ea07-1d8c43d43fe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/hisat2-align-s version 2.2.1\r\n",
      "64-bit\r\n",
      "Built on Nucleus005\r\n",
      "Wed Dec  2 16:48:17 CST 2020\r\n",
      "Compiler: gcc version 5.4.0 (GCC) \r\n",
      "Options: -O3 -m64 -msse2 -funroll-loops -g3 -DPOPCNT_CAPABILITY -std=c++11\r\n",
      "Sizeof {int, long, long long, void*, size_t, off_t}: {4, 8, 8, 8, 8, 8}\r\n"
     ]
    }
   ],
   "source": [
    "!hisat2 --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiVlP4mfy74q"
   },
   "source": [
    "## Установка FastQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62l1Q2ymbENA",
    "outputId": "cc47f193-b6a0-4092-9f7e-9f79c6c0e8f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"17.0.1\" 2021-10-19\r\n",
      "OpenJDK Runtime Environment (build 17.0.1+12)\r\n",
      "OpenJDK 64-Bit Server VM (build 17.0.1+12, mixed mode)\r\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bpgwFgcbgRd",
    "outputId": "119a044a-ecaa-4403-eb8c-18f6b0ff8802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘fastqc_v0.11.9.zip’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.9.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: multiqc in /home/sasha/.local/lib/python3.9/site-packages (1.11)\n",
      "Requirement already satisfied: pyyaml>=4 in /usr/lib/python3.9/site-packages (from multiqc) (5.4.1)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/lib/python3.9/site-packages (from multiqc) (2.6.3)\n",
      "Requirement already satisfied: click in /usr/lib/python3.9/site-packages (from multiqc) (8.0.3)\n",
      "Requirement already satisfied: markdown in /usr/lib/python3.9/site-packages (from multiqc) (3.3.6)\n",
      "Requirement already satisfied: lzstring in /home/sasha/.local/lib/python3.9/site-packages (from multiqc) (1.0.4)\n",
      "Requirement already satisfied: jinja2>=2.9 in /usr/lib/python3.9/site-packages (from multiqc) (3.0.3)\n",
      "Requirement already satisfied: matplotlib>=2.1.1 in /usr/lib/python3.9/site-packages (from multiqc) (3.5.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.9/site-packages (from multiqc) (2.26.0)\n",
      "Requirement already satisfied: simplejson in /home/sasha/.local/lib/python3.9/site-packages (from multiqc) (3.17.6)\n",
      "Requirement already satisfied: spectra>=0.0.10 in /home/sasha/.local/lib/python3.9/site-packages (from multiqc) (0.0.11)\n",
      "Requirement already satisfied: numpy in /home/sasha/.local/lib/python3.9/site-packages (from multiqc) (1.21.2)\n",
      "Requirement already satisfied: future>0.14.0 in /usr/lib/python3.9/site-packages (from multiqc) (0.18.2)\n",
      "Requirement already satisfied: rich>=10 in /usr/lib/python3.9/site-packages (from multiqc) (10.15.0)\n",
      "Requirement already satisfied: coloredlogs in /home/sasha/.local/lib/python3.9/site-packages (from multiqc) (15.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3.9/site-packages (from jinja2>=2.9->multiqc) (2.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3.9/site-packages (from matplotlib>=2.1.1->multiqc) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/lib/python3.9/site-packages (from matplotlib>=2.1.1->multiqc) (4.28.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib/python3.9/site-packages (from matplotlib>=2.1.1->multiqc) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.9/site-packages (from matplotlib>=2.1.1->multiqc) (20.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3.9/site-packages (from matplotlib>=2.1.1->multiqc) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3.9/site-packages (from matplotlib>=2.1.1->multiqc) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3.9/site-packages (from matplotlib>=2.1.1->multiqc) (2.8.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=2.1.1->multiqc) (1.16.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/lib/python3.9/site-packages (from rich>=10->multiqc) (0.9.1)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /usr/lib/python3.9/site-packages (from rich>=10->multiqc) (0.4.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/lib/python3.9/site-packages (from rich>=10->multiqc) (2.10.0)\n",
      "Requirement already satisfied: colormath>=3.0.0 in /home/sasha/.local/lib/python3.9/site-packages (from spectra>=0.0.10->multiqc) (3.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/sasha/.local/lib/python3.9/site-packages (from coloredlogs->multiqc) (10.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/lib/python3.9/site-packages (from markdown->multiqc) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown->multiqc) (3.6.0)\n",
      "Requirement already satisfied: chardet>=3.0.2 in /usr/lib/python3.9/site-packages (from requests->multiqc) (4.0.0)\n",
      "Requirement already satisfied: idna>=2.5 in /usr/lib/python3.9/site-packages (from requests->multiqc) (3.3)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3.9/site-packages (from requests->multiqc) (1.26.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install multiqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTcTjOTJblcm",
    "outputId": "abe9fd71-ca30-4122-c1b9-c3dc37d2056c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  fastqc_v0.11.9.zip\r\n"
     ]
    }
   ],
   "source": [
    "!unzip -n fastqc_v0.11.9.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "S79LH0aXbvLx"
   },
   "outputs": [],
   "source": [
    "!chmod a+x FastQC/fastqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PsLuZDt4b7jT",
    "outputId": "7fe4d3be-e275-4877-a543-de9682ee3ef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "            FastQC - A high throughput sequence QC analysis tool\r\n",
      "\r\n",
      "SYNOPSIS\r\n",
      "\r\n",
      "\tfastqc seqfile1 seqfile2 .. seqfileN\r\n",
      "\r\n",
      "    fastqc [-o output dir] [--(no)extract] [-f fastq|bam|sam] \r\n",
      "           [-c contaminant file] seqfile1 .. seqfileN\r\n",
      "\r\n",
      "DESCRIPTION\r\n",
      "\r\n",
      "    FastQC reads a set of sequence files and produces from each one a quality\r\n",
      "    control report consisting of a number of different modules, each one of \r\n",
      "    which will help to identify a different potential type of problem in your\r\n",
      "    data.\r\n",
      "    \r\n",
      "    If no files to process are specified on the command line then the program\r\n",
      "    will start as an interactive graphical application.  If files are provided\r\n",
      "    on the command line then the program will run with no user interaction\r\n",
      "    required.  In this mode it is suitable for inclusion into a standardised\r\n",
      "    analysis pipeline.\r\n",
      "    \r\n",
      "    The options for the program as as follows:\r\n",
      "    \r\n",
      "    -h --help       Print this help file and exit\r\n",
      "    \r\n",
      "    -v --version    Print the version of the program and exit\r\n",
      "    \r\n",
      "    -o --outdir     Create all output files in the specified output directory.\r\n",
      "                    Please note that this directory must exist as the program\r\n",
      "                    will not create it.  If this option is not set then the \r\n",
      "                    output file for each sequence file is created in the same\r\n",
      "                    directory as the sequence file which was processed.\r\n",
      "                    \r\n",
      "    --casava        Files come from raw casava output. Files in the same sample\r\n",
      "                    group (differing only by the group number) will be analysed\r\n",
      "                    as a set rather than individually. Sequences with the filter\r\n",
      "                    flag set in the header will be excluded from the analysis.\r\n",
      "                    Files must have the same names given to them by casava\r\n",
      "                    (including being gzipped and ending with .gz) otherwise they\r\n",
      "                    won't be grouped together correctly.\r\n",
      "                    \r\n",
      "    --nano          Files come from nanopore sequences and are in fast5 format. In\r\n",
      "                    this mode you can pass in directories to process and the program\r\n",
      "                    will take in all fast5 files within those directories and produce\r\n",
      "                    a single output file from the sequences found in all files.                    \r\n",
      "                    \r\n",
      "    --nofilter      If running with --casava then don't remove read flagged by\r\n",
      "                    casava as poor quality when performing the QC analysis.\r\n",
      "                   \r\n",
      "    --extract       If set then the zipped output file will be uncompressed in\r\n",
      "                    the same directory after it has been created.  By default\r\n",
      "                    this option will be set if fastqc is run in non-interactive\r\n",
      "                    mode.\r\n",
      "                    \r\n",
      "    -j --java       Provides the full path to the java binary you want to use to\r\n",
      "                    launch fastqc. If not supplied then java is assumed to be in\r\n",
      "                    your path.\r\n",
      "                   \r\n",
      "    --noextract     Do not uncompress the output file after creating it.  You\r\n",
      "                    should set this option if you do not wish to uncompress\r\n",
      "                    the output when running in non-interactive mode.\r\n",
      "                    \r\n",
      "    --nogroup       Disable grouping of bases for reads >50bp. All reports will\r\n",
      "                    show data for every base in the read.  WARNING: Using this\r\n",
      "                    option will cause fastqc to crash and burn if you use it on\r\n",
      "                    really long reads, and your plots may end up a ridiculous size.\r\n",
      "                    You have been warned!\r\n",
      "                    \r\n",
      "    --min_length    Sets an artificial lower limit on the length of the sequence\r\n",
      "                    to be shown in the report.  As long as you set this to a value\r\n",
      "                    greater or equal to your longest read length then this will be\r\n",
      "                    the sequence length used to create your read groups.  This can\r\n",
      "                    be useful for making directly comaparable statistics from \r\n",
      "                    datasets with somewhat variable read lengths.\r\n",
      "                    \r\n",
      "    -f --format     Bypasses the normal sequence file format detection and\r\n",
      "                    forces the program to use the specified format.  Valid\r\n",
      "                    formats are bam,sam,bam_mapped,sam_mapped and fastq\r\n",
      "                    \r\n",
      "    -t --threads    Specifies the number of files which can be processed\r\n",
      "                    simultaneously.  Each thread will be allocated 250MB of\r\n",
      "                    memory so you shouldn't run more threads than your\r\n",
      "                    available memory will cope with, and not more than\r\n",
      "                    6 threads on a 32 bit machine\r\n",
      "                  \r\n",
      "    -c              Specifies a non-default file which contains the list of\r\n",
      "    --contaminants  contaminants to screen overrepresented sequences against.\r\n",
      "                    The file must contain sets of named contaminants in the\r\n",
      "                    form name[tab]sequence.  Lines prefixed with a hash will\r\n",
      "                    be ignored.\r\n",
      "\r\n",
      "    -a              Specifies a non-default file which contains the list of\r\n",
      "    --adapters      adapter sequences which will be explicity searched against\r\n",
      "                    the library. The file must contain sets of named adapters\r\n",
      "                    in the form name[tab]sequence.  Lines prefixed with a hash\r\n",
      "                    will be ignored.\r\n",
      "                    \r\n",
      "    -l              Specifies a non-default file which contains a set of criteria\r\n",
      "    --limits        which will be used to determine the warn/error limits for the\r\n",
      "                    various modules.  This file can also be used to selectively \r\n",
      "                    remove some modules from the output all together.  The format\r\n",
      "                    needs to mirror the default limits.txt file found in the\r\n",
      "                    Configuration folder.\r\n",
      "                    \r\n",
      "   -k --kmers       Specifies the length of Kmer to look for in the Kmer content\r\n",
      "                    module. Specified Kmer length must be between 2 and 10. Default\r\n",
      "                    length is 7 if not specified.\r\n",
      "                    \r\n",
      "   -q --quiet       Supress all progress messages on stdout and only report errors.\r\n",
      "   \r\n",
      "   -d --dir         Selects a directory to be used for temporary files written when\r\n",
      "                    generating report images. Defaults to system temp directory if\r\n",
      "                    not specified.\r\n",
      "                    \r\n",
      "BUGS\r\n",
      "\r\n",
      "    Any bugs in fastqc should be reported either to simon.andrews@babraham.ac.uk\r\n",
      "    or in www.bioinformatics.babraham.ac.uk/bugzilla/\r\n",
      "                   \r\n",
      "    \r\n"
     ]
    }
   ],
   "source": [
    "!./FastQC/fastqc --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dqWpZZ_0_V-"
   },
   "source": [
    "## Установка HTSeq-count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7W0Ep2nhT_d",
    "outputId": "44b34b50-1c79-466c-c774-d6aa6cc171b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: htseq-count [options] alignment_file gff_file\r\n",
      "htseq-count: error: the following arguments are required: samfilenames, featuresfilename\r\n"
     ]
    }
   ],
   "source": [
    "!htseq-count --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6MhDf5N2tQ3"
   },
   "source": [
    "## Скачиваем RNA-seq данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LicIlxo028wE"
   },
   "source": [
    "* Перепрограммированные образцы: \tSRR3414629, SRR3414630, SRR3414631\n",
    "* Контрольные образцы:\t\tSRR3414635, SRR3414636, SRR3414637\n",
    "\n",
    "**Один образец скачивается 5-10 мин!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7-OCZli2z38",
    "outputId": "3aead6cc-d2a9-4cbe-d73f-73f2ad53fd27",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘rna_seq_2021.tgz’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc http://83.149.211.146:23194/~ivan/data/hse_teaching/rna_seq_2021.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rna_seq_2021/\n",
      "rna_seq_2021/_tmp.txt\n",
      "rna_seq_2021/SRR3414629_1.fastq\n",
      "rna_seq_2021/SRR3414636_1.fastq\n",
      "rna_seq_2021/SRR3414631_1.fastq\n",
      "rna_seq_2021/SRR3414635_1.fastq\n",
      "rna_seq_2021/SRR3414637_1.fastq\n",
      "rna_seq_2021/SRR3414630_1.fastq\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf rna_seq_2021.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAn1rivS0BME"
   },
   "source": [
    "## Скачиваем геном мыши mm10 (проиндексированный для HISAT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWfSQMGZ03Ch",
    "outputId": "fc056275-1ad4-4752-9279-e1c29f4158d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘mm10_genome.tar.gz’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://genome-idx.s3.amazonaws.com/hisat/mm10_genome.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IKaXKp7eLjq",
    "outputId": "775094fc-e1e5-415e-a83a-8d1c3ca100c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mm10/\n",
      "mm10/genome.8.ht2\n",
      "mm10/genome.5.ht2\n",
      "mm10/make_mm10.sh\n",
      "mm10/genome.7.ht2\n",
      "mm10/genome.6.ht2\n",
      "mm10/genome.4.ht2\n",
      "mm10/genome.3.ht2\n",
      "mm10/genome.1.ht2\n",
      "mm10/genome.2.ht2\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf mm10_genome.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGULD5P70tvT"
   },
   "source": [
    "## Скачиваем аннотацию генов GENCODE для генома мыши mm10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8SxMZMC3Aw-",
    "outputId": "e14d85b2-ce95-4df4-de7f-3194378d4bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘gencode.vM25.annotation.gtf.gz’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "K9RerBtX8iFF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: gencode.vM25.annotation.gtf already exists;\tnot overwritten\r\n",
      "yes: standard output: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!yes n | gzip -d gencode.vM25.annotation.gtf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzucvMQkzzs9"
   },
   "source": [
    "# Выравнивание чтений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bH70xoP87343"
   },
   "source": [
    "**Ниже приведены примеры запуска только для одного файла. Вам следует сделать это для всех 6-ти файлов.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRBfl7NL3xgN"
   },
   "source": [
    "* Для каждого образца запускаем FastQC. Скачиваем полученные html файлы и проверяем есть ли проблемы с файлами. Можно также установить multiqc и получить объединенный .html файл. Полученные результаты приводим в отчете на Github-е.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABkz3YC8cjhD",
    "outputId": "5a53dc35-c128-4c64-f094-1d79e426ec75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR3414629_1.fastq\n",
      "Approx 5% complete for SRR3414629_1.fastq\n",
      "Approx 10% complete for SRR3414629_1.fastq\n",
      "Approx 15% complete for SRR3414629_1.fastq\n",
      "Approx 20% complete for SRR3414629_1.fastq\n",
      "Approx 25% complete for SRR3414629_1.fastq\n",
      "Approx 30% complete for SRR3414629_1.fastq\n",
      "Approx 35% complete for SRR3414629_1.fastq\n",
      "Approx 40% complete for SRR3414629_1.fastq\n",
      "Approx 45% complete for SRR3414629_1.fastq\n",
      "Approx 50% complete for SRR3414629_1.fastq\n",
      "Approx 55% complete for SRR3414629_1.fastq\n",
      "Approx 60% complete for SRR3414629_1.fastq\n",
      "Approx 65% complete for SRR3414629_1.fastq\n",
      "Approx 70% complete for SRR3414629_1.fastq\n",
      "Approx 75% complete for SRR3414629_1.fastq\n",
      "Approx 80% complete for SRR3414629_1.fastq\n",
      "Approx 85% complete for SRR3414629_1.fastq\n",
      "Approx 90% complete for SRR3414629_1.fastq\n",
      "Approx 95% complete for SRR3414629_1.fastq\n",
      "Analysis complete for SRR3414629_1.fastq\n",
      "Started analysis of SRR3414630_1.fastq\n",
      "Approx 5% complete for SRR3414630_1.fastq\n",
      "Approx 10% complete for SRR3414630_1.fastq\n",
      "Approx 15% complete for SRR3414630_1.fastq\n",
      "Approx 20% complete for SRR3414630_1.fastq\n",
      "Approx 25% complete for SRR3414630_1.fastq\n",
      "Approx 30% complete for SRR3414630_1.fastq\n",
      "Approx 35% complete for SRR3414630_1.fastq\n",
      "Approx 40% complete for SRR3414630_1.fastq\n",
      "Approx 45% complete for SRR3414630_1.fastq\n",
      "Approx 50% complete for SRR3414630_1.fastq\n",
      "Approx 55% complete for SRR3414630_1.fastq\n",
      "Approx 60% complete for SRR3414630_1.fastq\n",
      "Approx 65% complete for SRR3414630_1.fastq\n",
      "Approx 70% complete for SRR3414630_1.fastq\n",
      "Approx 75% complete for SRR3414630_1.fastq\n",
      "Approx 80% complete for SRR3414630_1.fastq\n",
      "Approx 85% complete for SRR3414630_1.fastq\n",
      "Approx 90% complete for SRR3414630_1.fastq\n",
      "Approx 95% complete for SRR3414630_1.fastq\n",
      "Analysis complete for SRR3414630_1.fastq\n",
      "Started analysis of SRR3414631_1.fastq\n",
      "Approx 5% complete for SRR3414631_1.fastq\n",
      "Approx 10% complete for SRR3414631_1.fastq\n",
      "Approx 15% complete for SRR3414631_1.fastq\n",
      "Approx 20% complete for SRR3414631_1.fastq\n",
      "Approx 25% complete for SRR3414631_1.fastq\n",
      "Approx 30% complete for SRR3414631_1.fastq\n",
      "Approx 35% complete for SRR3414631_1.fastq\n",
      "Approx 40% complete for SRR3414631_1.fastq\n",
      "Approx 45% complete for SRR3414631_1.fastq\n",
      "Approx 50% complete for SRR3414631_1.fastq\n",
      "Approx 55% complete for SRR3414631_1.fastq\n",
      "Approx 60% complete for SRR3414631_1.fastq\n",
      "Approx 65% complete for SRR3414631_1.fastq\n",
      "Approx 70% complete for SRR3414631_1.fastq\n",
      "Approx 75% complete for SRR3414631_1.fastq\n",
      "Approx 80% complete for SRR3414631_1.fastq\n",
      "Approx 85% complete for SRR3414631_1.fastq\n",
      "Approx 90% complete for SRR3414631_1.fastq\n",
      "Approx 95% complete for SRR3414631_1.fastq\n",
      "Analysis complete for SRR3414631_1.fastq\n",
      "Started analysis of SRR3414635_1.fastq\n",
      "Approx 5% complete for SRR3414635_1.fastq\n",
      "Approx 10% complete for SRR3414635_1.fastq\n",
      "Approx 15% complete for SRR3414635_1.fastq\n",
      "Approx 20% complete for SRR3414635_1.fastq\n",
      "Approx 25% complete for SRR3414635_1.fastq\n",
      "Approx 30% complete for SRR3414635_1.fastq\n",
      "Approx 35% complete for SRR3414635_1.fastq\n",
      "Approx 40% complete for SRR3414635_1.fastq\n",
      "Approx 45% complete for SRR3414635_1.fastq\n",
      "Approx 50% complete for SRR3414635_1.fastq\n",
      "Approx 55% complete for SRR3414635_1.fastq\n",
      "Approx 60% complete for SRR3414635_1.fastq\n",
      "Approx 65% complete for SRR3414635_1.fastq\n",
      "Approx 70% complete for SRR3414635_1.fastq\n",
      "Approx 75% complete for SRR3414635_1.fastq\n",
      "Approx 80% complete for SRR3414635_1.fastq\n",
      "Approx 85% complete for SRR3414635_1.fastq\n",
      "Approx 90% complete for SRR3414635_1.fastq\n",
      "Approx 95% complete for SRR3414635_1.fastq\n",
      "Analysis complete for SRR3414635_1.fastq\n",
      "Started analysis of SRR3414636_1.fastq\n",
      "Approx 5% complete for SRR3414636_1.fastq\n",
      "Approx 10% complete for SRR3414636_1.fastq\n",
      "Approx 15% complete for SRR3414636_1.fastq\n",
      "Approx 20% complete for SRR3414636_1.fastq\n",
      "Approx 25% complete for SRR3414636_1.fastq\n",
      "Approx 30% complete for SRR3414636_1.fastq\n",
      "Approx 35% complete for SRR3414636_1.fastq\n",
      "Approx 40% complete for SRR3414636_1.fastq\n",
      "Approx 45% complete for SRR3414636_1.fastq\n",
      "Approx 50% complete for SRR3414636_1.fastq\n",
      "Approx 55% complete for SRR3414636_1.fastq\n",
      "Approx 60% complete for SRR3414636_1.fastq\n",
      "Approx 65% complete for SRR3414636_1.fastq\n",
      "Approx 70% complete for SRR3414636_1.fastq\n",
      "Approx 75% complete for SRR3414636_1.fastq\n",
      "Approx 80% complete for SRR3414636_1.fastq\n",
      "Approx 85% complete for SRR3414636_1.fastq\n",
      "Approx 90% complete for SRR3414636_1.fastq\n",
      "Approx 95% complete for SRR3414636_1.fastq\n",
      "Analysis complete for SRR3414636_1.fastq\n",
      "Started analysis of SRR3414637_1.fastq\n",
      "Approx 5% complete for SRR3414637_1.fastq\n",
      "Approx 10% complete for SRR3414637_1.fastq\n",
      "Approx 15% complete for SRR3414637_1.fastq\n",
      "Approx 20% complete for SRR3414637_1.fastq\n",
      "Approx 25% complete for SRR3414637_1.fastq\n",
      "Approx 30% complete for SRR3414637_1.fastq\n",
      "Approx 35% complete for SRR3414637_1.fastq\n",
      "Approx 40% complete for SRR3414637_1.fastq\n",
      "Approx 45% complete for SRR3414637_1.fastq\n",
      "Approx 50% complete for SRR3414637_1.fastq\n",
      "Approx 55% complete for SRR3414637_1.fastq\n",
      "Approx 60% complete for SRR3414637_1.fastq\n",
      "Approx 65% complete for SRR3414637_1.fastq\n",
      "Approx 70% complete for SRR3414637_1.fastq\n",
      "Approx 75% complete for SRR3414637_1.fastq\n",
      "Approx 80% complete for SRR3414637_1.fastq\n",
      "Approx 85% complete for SRR3414637_1.fastq\n",
      "Approx 90% complete for SRR3414637_1.fastq\n",
      "Approx 95% complete for SRR3414637_1.fastq\n",
      "Analysis complete for SRR3414637_1.fastq\n"
     ]
    }
   ],
   "source": [
    "!./FastQC/fastqc  ./rna_seq_2021/SRR3414629_1.fastq\n",
    "!./FastQC/fastqc  ./rna_seq_2021/SRR3414630_1.fastq\n",
    "!./FastQC/fastqc  ./rna_seq_2021/SRR3414631_1.fastq\n",
    "!./FastQC/fastqc  ./rna_seq_2021/SRR3414635_1.fastq\n",
    "!./FastQC/fastqc  ./rna_seq_2021/SRR3414636_1.fastq\n",
    "!./FastQC/fastqc  ./rna_seq_2021/SRR3414637_1.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b23N89JW4Eeg"
   },
   "source": [
    "* Запускаем HISAT2 и картируем все чтения на геном мыши.\n",
    "* **Для одного образца программа работает 10-15 мин**\n",
    "* Общее кол-во чтений, и кол-во, которое удалось успешно откартировать (уникально и не уникально), указано в файле SRR3414636.hisat. Приводим эту информацию в отчете на Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "us6WSL8Ge6U_",
    "outputId": "f1ba1a4a-7986-40a5-99b6-7614dd032362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hisat2 -p 3 -x mm10/genome -U ./rna_seq_2021/SRR3414629_1.fastq -S  2>   479,65s user 19,09s system 293% cpu 2:49,90 total\n",
      "hisat2 -p 3 -x mm10/genome -U ./rna_seq_2021/SRR3414630_1.fastq -S  2>   347,03s user 18,60s system 289% cpu 2:06,20 total\n",
      "hisat2 -p 3 -x mm10/genome -U ./rna_seq_2021/SRR3414631_1.fastq -S  2>   565,51s user 33,38s system 290% cpu 3:26,32 total\n",
      "hisat2 -p 3 -x mm10/genome -U ./rna_seq_2021/SRR3414635_1.fastq -S  2>   464,70s user 27,20s system 288% cpu 2:50,51 total\n",
      "hisat2 -p 3 -x mm10/genome -U ./rna_seq_2021/SRR3414636_1.fastq -S  2>   452,18s user 25,87s system 290% cpu 2:44,73 total\n",
      "hisat2 -p 3 -x mm10/genome -U ./rna_seq_2021/SRR3414637_1.fastq -S  2>   449,46s user 25,37s system 290% cpu 2:43,70 total\n"
     ]
    }
   ],
   "source": [
    "!time hisat2 -p 3 -x mm10/genome -U ./rna_seq_2021/SRR3414629_1.fastq -S SRR3414629_1.sam  2>  SRR3414629.hisat\n",
    "!time hisat2 -p 3 -x mm10/genome -U ./rna_seq_2021/SRR3414630_1.fastq -S SRR3414630_1.sam  2>  SRR3414630.hisat\n",
    "!time hisat2 -p 3 -x mm10/genome -U ./rna_seq_2021/SRR3414631_1.fastq -S SRR3414631_1.sam  2>  SRR3414631.hisat\n",
    "!time hisat2 -p 3 -x mm10/genome -U ./rna_seq_2021/SRR3414635_1.fastq -S SRR3414635_1.sam  2>  SRR3414635.hisat\n",
    "!time hisat2 -p 3 -x mm10/genome -U ./rna_seq_2021/SRR3414636_1.fastq -S SRR3414636_1.sam  2>  SRR3414636.hisat\n",
    "!time hisat2 -p 3 -x mm10/genome -U ./rna_seq_2021/SRR3414637_1.fastq -S SRR3414637_1.sam  2>  SRR3414637.hisat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IMvdwqr0_BA1",
    "outputId": "da942649-22ae-48b9-e5d5-4e0d5a9207ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21106089 reads; of these:\r\n",
      "  21106089 (100.00%) were unpaired; of these:\r\n",
      "    241118 (1.14%) aligned 0 times\r\n",
      "    18573565 (88.00%) aligned exactly 1 time\r\n",
      "    2291406 (10.86%) aligned >1 times\r\n",
      "98.86% overall alignment rate\r\n"
     ]
    }
   ],
   "source": [
    "!cat SRR3414629.hisat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15244711 reads; of these:\r\n",
      "  15244711 (100.00%) were unpaired; of these:\r\n",
      "    168274 (1.10%) aligned 0 times\r\n",
      "    13320505 (87.38%) aligned exactly 1 time\r\n",
      "    1755932 (11.52%) aligned >1 times\r\n",
      "98.90% overall alignment rate\r\n"
     ]
    }
   ],
   "source": [
    "!cat SRR3414630.hisat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24244069 reads; of these:\r\n",
      "  24244069 (100.00%) were unpaired; of these:\r\n",
      "    279694 (1.15%) aligned 0 times\r\n",
      "    21159606 (87.28%) aligned exactly 1 time\r\n",
      "    2804769 (11.57%) aligned >1 times\r\n",
      "98.85% overall alignment rate\r\n"
     ]
    }
   ],
   "source": [
    "!cat SRR3414631.hisat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20956475 reads; of these:\r\n",
      "  20956475 (100.00%) were unpaired; of these:\r\n",
      "    242044 (1.15%) aligned 0 times\r\n",
      "    18637053 (88.93%) aligned exactly 1 time\r\n",
      "    2077378 (9.91%) aligned >1 times\r\n",
      "98.85% overall alignment rate\r\n"
     ]
    }
   ],
   "source": [
    "!cat SRR3414635.hisat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20307147 reads; of these:\r\n",
      "  20307147 (100.00%) were unpaired; of these:\r\n",
      "    233551 (1.15%) aligned 0 times\r\n",
      "    18032679 (88.80%) aligned exactly 1 time\r\n",
      "    2040917 (10.05%) aligned >1 times\r\n",
      "98.85% overall alignment rate\r\n"
     ]
    }
   ],
   "source": [
    "!cat SRR3414636.hisat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20385570 reads; of these:\r\n",
      "  20385570 (100.00%) were unpaired; of these:\r\n",
      "    236895 (1.16%) aligned 0 times\r\n",
      "    18043406 (88.51%) aligned exactly 1 time\r\n",
      "    2105269 (10.33%) aligned >1 times\r\n",
      "98.84% overall alignment rate\r\n"
     ]
    }
   ],
   "source": [
    "!cat SRR3414637.hisat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7NUQXYU8C3w"
   },
   "source": [
    "* Отбираем только те чтения, которые откартировались уникально (флаг NH:i:1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0scVvWyz8Gjk"
   },
   "outputs": [],
   "source": [
    "!grep -P '^@|NH:i:1$' SRR3414629_1.sam > SRR3414629.uniq.sam\n",
    "!grep -P '^@|NH:i:1$' SRR3414630_1.sam > SRR3414630.uniq.sam\n",
    "!grep -P '^@|NH:i:1$' SRR3414631_1.sam > SRR3414631.uniq.sam\n",
    "!grep -P '^@|NH:i:1$' SRR3414635_1.sam > SRR3414635.uniq.sam\n",
    "!grep -P '^@|NH:i:1$' SRR3414636_1.sam > SRR3414636.uniq.sam\n",
    "!grep -P '^@|NH:i:1$' SRR3414637_1.sam > SRR3414637.uniq.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntVSwG4xHHfY"
   },
   "source": [
    "* Удаляем исходные .sam файлы, т.к. они нам больше не потребуются:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "CHL0L7bvHJ8Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'SRR3414629_1.sam'\n",
      "removed 'SRR3414630_1.sam'\n",
      "removed 'SRR3414631_1.sam'\n",
      "removed 'SRR3414635_1.sam'\n",
      "removed 'SRR3414636_1.sam'\n",
      "removed 'SRR3414637_1.sam'\n"
     ]
    }
   ],
   "source": [
    "!rm -v *_1.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeH868YM8RKT"
   },
   "source": [
    "* Считаем кол-во уникально-картированных чтений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBdA-OAz_nvx",
    "outputId": "63b8e2bf-92ac-4ee6-e9ff-37728e3523ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18573565\r\n"
     ]
    }
   ],
   "source": [
    "!grep -v '^@' SRR3414629.uniq.sam | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBdA-OAz_nvx",
    "outputId": "63b8e2bf-92ac-4ee6-e9ff-37728e3523ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13320505\r\n"
     ]
    }
   ],
   "source": [
    "!grep -v '^@' SRR3414630.uniq.sam | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBdA-OAz_nvx",
    "outputId": "63b8e2bf-92ac-4ee6-e9ff-37728e3523ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21159606\r\n"
     ]
    }
   ],
   "source": [
    "!grep -v '^@' SRR3414631.uniq.sam | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBdA-OAz_nvx",
    "outputId": "63b8e2bf-92ac-4ee6-e9ff-37728e3523ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18637053\r\n"
     ]
    }
   ],
   "source": [
    "!grep -v '^@' SRR3414635.uniq.sam | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBdA-OAz_nvx",
    "outputId": "63b8e2bf-92ac-4ee6-e9ff-37728e3523ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18032679\r\n"
     ]
    }
   ],
   "source": [
    "!grep -v '^@' SRR3414636.uniq.sam | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBdA-OAz_nvx",
    "outputId": "63b8e2bf-92ac-4ee6-e9ff-37728e3523ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18043406\r\n"
     ]
    }
   ],
   "source": [
    "!grep -v '^@' SRR3414637.uniq.sam | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JqUV4J_8a8h"
   },
   "source": [
    "* С помощью программы `HTSeq` Подсчитываем количество чтений, попавших на каждый ген (**для одного образца программа работает 15-20 мин**):\n",
    "* Аннтоация генома мыши в формате .gtf находится в файле `gencode.vM25.annotation.gtf`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7IHTD5Ihorm",
    "outputId": "ec8f97d1-65ef-485b-ebdf-e0160afab6b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1872052 GFF lines processed.\n",
      "100000 SAM alignment records processed.\n",
      "200000 SAM alignment records processed.\n",
      "300000 SAM alignment records processed.\n",
      "400000 SAM alignment records processed.\n",
      "500000 SAM alignment records processed.\n",
      "600000 SAM alignment records processed.\n",
      "700000 SAM alignment records processed.\n",
      "800000 SAM alignment records processed.\n",
      "900000 SAM alignment records processed.\n",
      "1000000 SAM alignment records processed.\n",
      "1100000 SAM alignment records processed.\n",
      "1200000 SAM alignment records processed.\n",
      "1300000 SAM alignment records processed.\n",
      "1400000 SAM alignment records processed.\n",
      "1500000 SAM alignment records processed.\n",
      "1600000 SAM alignment records processed.\n",
      "1700000 SAM alignment records processed.\n",
      "1800000 SAM alignment records processed.\n",
      "1900000 SAM alignment records processed.\n",
      "2000000 SAM alignment records processed.\n",
      "2100000 SAM alignment records processed.\n",
      "2200000 SAM alignment records processed.\n",
      "2300000 SAM alignment records processed.\n",
      "2400000 SAM alignment records processed.\n",
      "2500000 SAM alignment records processed.\n",
      "2600000 SAM alignment records processed.\n",
      "2700000 SAM alignment records processed.\n",
      "2800000 SAM alignment records processed.\n",
      "2900000 SAM alignment records processed.\n",
      "3000000 SAM alignment records processed.\n",
      "3100000 SAM alignment records processed.\n",
      "3200000 SAM alignment records processed.\n",
      "3300000 SAM alignment records processed.\n",
      "3400000 SAM alignment records processed.\n",
      "3500000 SAM alignment records processed.\n",
      "3600000 SAM alignment records processed.\n",
      "3700000 SAM alignment records processed.\n",
      "3800000 SAM alignment records processed.\n",
      "3900000 SAM alignment records processed.\n",
      "4000000 SAM alignment records processed.\n",
      "4100000 SAM alignment records processed.\n",
      "4200000 SAM alignment records processed.\n",
      "4300000 SAM alignment records processed.\n",
      "4400000 SAM alignment records processed.\n",
      "4500000 SAM alignment records processed.\n",
      "4600000 SAM alignment records processed.\n",
      "4700000 SAM alignment records processed.\n",
      "4800000 SAM alignment records processed.\n",
      "4900000 SAM alignment records processed.\n",
      "5000000 SAM alignment records processed.\n",
      "5100000 SAM alignment records processed.\n",
      "5200000 SAM alignment records processed.\n",
      "5300000 SAM alignment records processed.\n",
      "5400000 SAM alignment records processed.\n",
      "5500000 SAM alignment records processed.\n",
      "5600000 SAM alignment records processed.\n",
      "5700000 SAM alignment records processed.\n",
      "5800000 SAM alignment records processed.\n",
      "5900000 SAM alignment records processed.\n",
      "6000000 SAM alignment records processed.\n",
      "6100000 SAM alignment records processed.\n",
      "6200000 SAM alignment records processed.\n",
      "6300000 SAM alignment records processed.\n",
      "6400000 SAM alignment records processed.\n",
      "6500000 SAM alignment records processed.\n",
      "6600000 SAM alignment records processed.\n",
      "6700000 SAM alignment records processed.\n",
      "6800000 SAM alignment records processed.\n",
      "6900000 SAM alignment records processed.\n",
      "7000000 SAM alignment records processed.\n",
      "7100000 SAM alignment records processed.\n",
      "7200000 SAM alignment records processed.\n",
      "7300000 SAM alignment records processed.\n",
      "7400000 SAM alignment records processed.\n",
      "7500000 SAM alignment records processed.\n",
      "7600000 SAM alignment records processed.\n",
      "7700000 SAM alignment records processed.\n",
      "7800000 SAM alignment records processed.\n",
      "7900000 SAM alignment records processed.\n",
      "8000000 SAM alignment records processed.\n",
      "8100000 SAM alignment records processed.\n",
      "8200000 SAM alignment records processed.\n",
      "8300000 SAM alignment records processed.\n",
      "8400000 SAM alignment records processed.\n",
      "8500000 SAM alignment records processed.\n",
      "8600000 SAM alignment records processed.\n",
      "8700000 SAM alignment records processed.\n",
      "8800000 SAM alignment records processed.\n",
      "8900000 SAM alignment records processed.\n",
      "9000000 SAM alignment records processed.\n",
      "9100000 SAM alignment records processed.\n",
      "9200000 SAM alignment records processed.\n",
      "9300000 SAM alignment records processed.\n",
      "9400000 SAM alignment records processed.\n",
      "9500000 SAM alignment records processed.\n",
      "9600000 SAM alignment records processed.\n",
      "9700000 SAM alignment records processed.\n",
      "9800000 SAM alignment records processed.\n",
      "9900000 SAM alignment records processed.\n",
      "10000000 SAM alignment records processed.\n",
      "10100000 SAM alignment records processed.\n",
      "10200000 SAM alignment records processed.\n",
      "10300000 SAM alignment records processed.\n",
      "10400000 SAM alignment records processed.\n",
      "10500000 SAM alignment records processed.\n",
      "10600000 SAM alignment records processed.\n",
      "10700000 SAM alignment records processed.\n",
      "10800000 SAM alignment records processed.\n",
      "10900000 SAM alignment records processed.\n",
      "11000000 SAM alignment records processed.\n",
      "11100000 SAM alignment records processed.\n",
      "11200000 SAM alignment records processed.\n",
      "11300000 SAM alignment records processed.\n",
      "11400000 SAM alignment records processed.\n",
      "11500000 SAM alignment records processed.\n",
      "11600000 SAM alignment records processed.\n",
      "11700000 SAM alignment records processed.\n",
      "11800000 SAM alignment records processed.\n",
      "11900000 SAM alignment records processed.\n",
      "12000000 SAM alignment records processed.\n",
      "12100000 SAM alignment records processed.\n",
      "12200000 SAM alignment records processed.\n",
      "12300000 SAM alignment records processed.\n",
      "12400000 SAM alignment records processed.\n",
      "12500000 SAM alignment records processed.\n",
      "12600000 SAM alignment records processed.\n",
      "12700000 SAM alignment records processed.\n",
      "12800000 SAM alignment records processed.\n",
      "12900000 SAM alignment records processed.\n",
      "13000000 SAM alignment records processed.\n",
      "13100000 SAM alignment records processed.\n",
      "13200000 SAM alignment records processed.\n",
      "13300000 SAM alignment records processed.\n",
      "13400000 SAM alignment records processed.\n",
      "13500000 SAM alignment records processed.\n",
      "13600000 SAM alignment records processed.\n",
      "13700000 SAM alignment records processed.\n",
      "13800000 SAM alignment records processed.\n",
      "13900000 SAM alignment records processed.\n",
      "14000000 SAM alignment records processed.\n",
      "14100000 SAM alignment records processed.\n",
      "14200000 SAM alignment records processed.\n",
      "14300000 SAM alignment records processed.\n",
      "14400000 SAM alignment records processed.\n",
      "14500000 SAM alignment records processed.\n",
      "14600000 SAM alignment records processed.\n",
      "14700000 SAM alignment records processed.\n",
      "14800000 SAM alignment records processed.\n",
      "14900000 SAM alignment records processed.\n",
      "15000000 SAM alignment records processed.\n",
      "15100000 SAM alignment records processed.\n",
      "15200000 SAM alignment records processed.\n",
      "15300000 SAM alignment records processed.\n",
      "15400000 SAM alignment records processed.\n",
      "15500000 SAM alignment records processed.\n",
      "15600000 SAM alignment records processed.\n",
      "15700000 SAM alignment records processed.\n",
      "15800000 SAM alignment records processed.\n",
      "15900000 SAM alignment records processed.\n",
      "16000000 SAM alignment records processed.\n",
      "16100000 SAM alignment records processed.\n",
      "16200000 SAM alignment records processed.\n",
      "16300000 SAM alignment records processed.\n",
      "16400000 SAM alignment records processed.\n",
      "16500000 SAM alignment records processed.\n",
      "16600000 SAM alignment records processed.\n",
      "16700000 SAM alignment records processed.\n",
      "16800000 SAM alignment records processed.\n",
      "16900000 SAM alignment records processed.\n",
      "17000000 SAM alignment records processed.\n",
      "17100000 SAM alignment records processed.\n",
      "17200000 SAM alignment records processed.\n",
      "17300000 SAM alignment records processed.\n",
      "17400000 SAM alignment records processed.\n",
      "17500000 SAM alignment records processed.\n",
      "17600000 SAM alignment records processed.\n",
      "17700000 SAM alignment records processed.\n",
      "17800000 SAM alignment records processed.\n",
      "17900000 SAM alignment records processed.\n",
      "18000000 SAM alignment records processed.\n",
      "18100000 SAM alignment records processed.\n",
      "18200000 SAM alignment records processed.\n",
      "18300000 SAM alignment records processed.\n",
      "18400000 SAM alignment records processed.\n",
      "18500000 SAM alignment records processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18573565 SAM alignments  processed.\n",
      "htseq-count --format=sam --stranded=no SRR3414629.uniq.sam  >   343,47s user 2,87s system 100% cpu 5:45,96 total\n",
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1872052 GFF lines processed.\n",
      "100000 SAM alignment records processed.\n",
      "200000 SAM alignment records processed.\n",
      "300000 SAM alignment records processed.\n",
      "400000 SAM alignment records processed.\n",
      "500000 SAM alignment records processed.\n",
      "600000 SAM alignment records processed.\n",
      "700000 SAM alignment records processed.\n",
      "800000 SAM alignment records processed.\n",
      "900000 SAM alignment records processed.\n",
      "1000000 SAM alignment records processed.\n",
      "1100000 SAM alignment records processed.\n",
      "1200000 SAM alignment records processed.\n",
      "1300000 SAM alignment records processed.\n",
      "1400000 SAM alignment records processed.\n",
      "1500000 SAM alignment records processed.\n",
      "1600000 SAM alignment records processed.\n",
      "1700000 SAM alignment records processed.\n",
      "1800000 SAM alignment records processed.\n",
      "1900000 SAM alignment records processed.\n",
      "2000000 SAM alignment records processed.\n",
      "2100000 SAM alignment records processed.\n",
      "2200000 SAM alignment records processed.\n",
      "2300000 SAM alignment records processed.\n",
      "2400000 SAM alignment records processed.\n",
      "2500000 SAM alignment records processed.\n",
      "2600000 SAM alignment records processed.\n",
      "2700000 SAM alignment records processed.\n",
      "2800000 SAM alignment records processed.\n",
      "2900000 SAM alignment records processed.\n",
      "3000000 SAM alignment records processed.\n",
      "3100000 SAM alignment records processed.\n",
      "3200000 SAM alignment records processed.\n",
      "3300000 SAM alignment records processed.\n",
      "3400000 SAM alignment records processed.\n",
      "3500000 SAM alignment records processed.\n",
      "3600000 SAM alignment records processed.\n",
      "3700000 SAM alignment records processed.\n",
      "3800000 SAM alignment records processed.\n",
      "3900000 SAM alignment records processed.\n",
      "4000000 SAM alignment records processed.\n",
      "4100000 SAM alignment records processed.\n",
      "4200000 SAM alignment records processed.\n",
      "4300000 SAM alignment records processed.\n",
      "4400000 SAM alignment records processed.\n",
      "4500000 SAM alignment records processed.\n",
      "4600000 SAM alignment records processed.\n",
      "4700000 SAM alignment records processed.\n",
      "4800000 SAM alignment records processed.\n",
      "4900000 SAM alignment records processed.\n",
      "5000000 SAM alignment records processed.\n",
      "5100000 SAM alignment records processed.\n",
      "5200000 SAM alignment records processed.\n",
      "5300000 SAM alignment records processed.\n",
      "5400000 SAM alignment records processed.\n",
      "5500000 SAM alignment records processed.\n",
      "5600000 SAM alignment records processed.\n",
      "5700000 SAM alignment records processed.\n",
      "5800000 SAM alignment records processed.\n",
      "5900000 SAM alignment records processed.\n",
      "6000000 SAM alignment records processed.\n",
      "6100000 SAM alignment records processed.\n",
      "6200000 SAM alignment records processed.\n",
      "6300000 SAM alignment records processed.\n",
      "6400000 SAM alignment records processed.\n",
      "6500000 SAM alignment records processed.\n",
      "6600000 SAM alignment records processed.\n",
      "6700000 SAM alignment records processed.\n",
      "6800000 SAM alignment records processed.\n",
      "6900000 SAM alignment records processed.\n",
      "7000000 SAM alignment records processed.\n",
      "7100000 SAM alignment records processed.\n",
      "7200000 SAM alignment records processed.\n",
      "7300000 SAM alignment records processed.\n",
      "7400000 SAM alignment records processed.\n",
      "7500000 SAM alignment records processed.\n",
      "7600000 SAM alignment records processed.\n",
      "7700000 SAM alignment records processed.\n",
      "7800000 SAM alignment records processed.\n",
      "7900000 SAM alignment records processed.\n",
      "8000000 SAM alignment records processed.\n",
      "8100000 SAM alignment records processed.\n",
      "8200000 SAM alignment records processed.\n",
      "8300000 SAM alignment records processed.\n",
      "8400000 SAM alignment records processed.\n",
      "8500000 SAM alignment records processed.\n",
      "8600000 SAM alignment records processed.\n",
      "8700000 SAM alignment records processed.\n",
      "8800000 SAM alignment records processed.\n",
      "8900000 SAM alignment records processed.\n",
      "9000000 SAM alignment records processed.\n",
      "9100000 SAM alignment records processed.\n",
      "9200000 SAM alignment records processed.\n",
      "9300000 SAM alignment records processed.\n",
      "9400000 SAM alignment records processed.\n",
      "9500000 SAM alignment records processed.\n",
      "9600000 SAM alignment records processed.\n",
      "9700000 SAM alignment records processed.\n",
      "9800000 SAM alignment records processed.\n",
      "9900000 SAM alignment records processed.\n",
      "10000000 SAM alignment records processed.\n",
      "10100000 SAM alignment records processed.\n",
      "10200000 SAM alignment records processed.\n",
      "10300000 SAM alignment records processed.\n",
      "10400000 SAM alignment records processed.\n",
      "10500000 SAM alignment records processed.\n",
      "10600000 SAM alignment records processed.\n",
      "10700000 SAM alignment records processed.\n",
      "10800000 SAM alignment records processed.\n",
      "10900000 SAM alignment records processed.\n",
      "11000000 SAM alignment records processed.\n",
      "11100000 SAM alignment records processed.\n",
      "11200000 SAM alignment records processed.\n",
      "11300000 SAM alignment records processed.\n",
      "11400000 SAM alignment records processed.\n",
      "11500000 SAM alignment records processed.\n",
      "11600000 SAM alignment records processed.\n",
      "11700000 SAM alignment records processed.\n",
      "11800000 SAM alignment records processed.\n",
      "11900000 SAM alignment records processed.\n",
      "12000000 SAM alignment records processed.\n",
      "12100000 SAM alignment records processed.\n",
      "12200000 SAM alignment records processed.\n",
      "12300000 SAM alignment records processed.\n",
      "12400000 SAM alignment records processed.\n",
      "12500000 SAM alignment records processed.\n",
      "12600000 SAM alignment records processed.\n",
      "12700000 SAM alignment records processed.\n",
      "12800000 SAM alignment records processed.\n",
      "12900000 SAM alignment records processed.\n",
      "13000000 SAM alignment records processed.\n",
      "13100000 SAM alignment records processed.\n",
      "13200000 SAM alignment records processed.\n",
      "13300000 SAM alignment records processed.\n",
      "13320505 SAM alignments  processed.\n",
      "htseq-count --format=sam --stranded=no SRR3414630.uniq.sam  >   251,36s user 2,59s system 100% cpu 4:13,21 total\n",
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1872052 GFF lines processed.\n",
      "100000 SAM alignment records processed.\n",
      "200000 SAM alignment records processed.\n",
      "300000 SAM alignment records processed.\n",
      "400000 SAM alignment records processed.\n",
      "500000 SAM alignment records processed.\n",
      "600000 SAM alignment records processed.\n",
      "700000 SAM alignment records processed.\n",
      "800000 SAM alignment records processed.\n",
      "900000 SAM alignment records processed.\n",
      "1000000 SAM alignment records processed.\n",
      "1100000 SAM alignment records processed.\n",
      "1200000 SAM alignment records processed.\n",
      "1300000 SAM alignment records processed.\n",
      "1400000 SAM alignment records processed.\n",
      "1500000 SAM alignment records processed.\n",
      "1600000 SAM alignment records processed.\n",
      "1700000 SAM alignment records processed.\n",
      "1800000 SAM alignment records processed.\n",
      "1900000 SAM alignment records processed.\n",
      "2000000 SAM alignment records processed.\n",
      "2100000 SAM alignment records processed.\n",
      "2200000 SAM alignment records processed.\n",
      "2300000 SAM alignment records processed.\n",
      "2400000 SAM alignment records processed.\n",
      "2500000 SAM alignment records processed.\n",
      "2600000 SAM alignment records processed.\n",
      "2700000 SAM alignment records processed.\n",
      "2800000 SAM alignment records processed.\n",
      "2900000 SAM alignment records processed.\n",
      "3000000 SAM alignment records processed.\n",
      "3100000 SAM alignment records processed.\n",
      "3200000 SAM alignment records processed.\n",
      "3300000 SAM alignment records processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400000 SAM alignment records processed.\n",
      "3500000 SAM alignment records processed.\n",
      "3600000 SAM alignment records processed.\n",
      "3700000 SAM alignment records processed.\n",
      "3800000 SAM alignment records processed.\n",
      "3900000 SAM alignment records processed.\n",
      "4000000 SAM alignment records processed.\n",
      "4100000 SAM alignment records processed.\n",
      "4200000 SAM alignment records processed.\n",
      "4300000 SAM alignment records processed.\n",
      "4400000 SAM alignment records processed.\n",
      "4500000 SAM alignment records processed.\n",
      "4600000 SAM alignment records processed.\n",
      "4700000 SAM alignment records processed.\n",
      "4800000 SAM alignment records processed.\n",
      "4900000 SAM alignment records processed.\n",
      "5000000 SAM alignment records processed.\n",
      "5100000 SAM alignment records processed.\n",
      "5200000 SAM alignment records processed.\n",
      "5300000 SAM alignment records processed.\n",
      "5400000 SAM alignment records processed.\n",
      "5500000 SAM alignment records processed.\n",
      "5600000 SAM alignment records processed.\n",
      "5700000 SAM alignment records processed.\n",
      "5800000 SAM alignment records processed.\n",
      "5900000 SAM alignment records processed.\n",
      "6000000 SAM alignment records processed.\n",
      "6100000 SAM alignment records processed.\n",
      "6200000 SAM alignment records processed.\n",
      "6300000 SAM alignment records processed.\n",
      "6400000 SAM alignment records processed.\n",
      "6500000 SAM alignment records processed.\n",
      "6600000 SAM alignment records processed.\n",
      "6700000 SAM alignment records processed.\n",
      "6800000 SAM alignment records processed.\n",
      "6900000 SAM alignment records processed.\n",
      "7000000 SAM alignment records processed.\n",
      "7100000 SAM alignment records processed.\n",
      "7200000 SAM alignment records processed.\n",
      "7300000 SAM alignment records processed.\n",
      "7400000 SAM alignment records processed.\n",
      "7500000 SAM alignment records processed.\n",
      "7600000 SAM alignment records processed.\n",
      "7700000 SAM alignment records processed.\n",
      "7800000 SAM alignment records processed.\n",
      "7900000 SAM alignment records processed.\n",
      "8000000 SAM alignment records processed.\n",
      "8100000 SAM alignment records processed.\n",
      "8200000 SAM alignment records processed.\n",
      "8300000 SAM alignment records processed.\n",
      "8400000 SAM alignment records processed.\n",
      "8500000 SAM alignment records processed.\n",
      "8600000 SAM alignment records processed.\n",
      "8700000 SAM alignment records processed.\n",
      "8800000 SAM alignment records processed.\n",
      "8900000 SAM alignment records processed.\n",
      "9000000 SAM alignment records processed.\n",
      "9100000 SAM alignment records processed.\n",
      "9200000 SAM alignment records processed.\n",
      "9300000 SAM alignment records processed.\n",
      "9400000 SAM alignment records processed.\n",
      "9500000 SAM alignment records processed.\n",
      "9600000 SAM alignment records processed.\n",
      "9700000 SAM alignment records processed.\n",
      "9800000 SAM alignment records processed.\n",
      "9900000 SAM alignment records processed.\n",
      "10000000 SAM alignment records processed.\n",
      "10100000 SAM alignment records processed.\n",
      "10200000 SAM alignment records processed.\n",
      "10300000 SAM alignment records processed.\n",
      "10400000 SAM alignment records processed.\n",
      "10500000 SAM alignment records processed.\n",
      "10600000 SAM alignment records processed.\n",
      "10700000 SAM alignment records processed.\n",
      "10800000 SAM alignment records processed.\n",
      "10900000 SAM alignment records processed.\n",
      "11000000 SAM alignment records processed.\n",
      "11100000 SAM alignment records processed.\n",
      "11200000 SAM alignment records processed.\n",
      "11300000 SAM alignment records processed.\n",
      "11400000 SAM alignment records processed.\n",
      "11500000 SAM alignment records processed.\n",
      "11600000 SAM alignment records processed.\n",
      "11700000 SAM alignment records processed.\n",
      "11800000 SAM alignment records processed.\n",
      "11900000 SAM alignment records processed.\n",
      "12000000 SAM alignment records processed.\n",
      "12100000 SAM alignment records processed.\n",
      "12200000 SAM alignment records processed.\n",
      "12300000 SAM alignment records processed.\n",
      "12400000 SAM alignment records processed.\n",
      "12500000 SAM alignment records processed.\n",
      "12600000 SAM alignment records processed.\n",
      "12700000 SAM alignment records processed.\n",
      "12800000 SAM alignment records processed.\n",
      "12900000 SAM alignment records processed.\n",
      "13000000 SAM alignment records processed.\n",
      "13100000 SAM alignment records processed.\n",
      "13200000 SAM alignment records processed.\n",
      "13300000 SAM alignment records processed.\n",
      "13400000 SAM alignment records processed.\n",
      "13500000 SAM alignment records processed.\n",
      "13600000 SAM alignment records processed.\n",
      "13700000 SAM alignment records processed.\n",
      "13800000 SAM alignment records processed.\n",
      "13900000 SAM alignment records processed.\n",
      "14000000 SAM alignment records processed.\n",
      "14100000 SAM alignment records processed.\n",
      "14200000 SAM alignment records processed.\n",
      "14300000 SAM alignment records processed.\n",
      "14400000 SAM alignment records processed.\n",
      "14500000 SAM alignment records processed.\n",
      "14600000 SAM alignment records processed.\n",
      "14700000 SAM alignment records processed.\n",
      "14800000 SAM alignment records processed.\n",
      "14900000 SAM alignment records processed.\n",
      "15000000 SAM alignment records processed.\n",
      "15100000 SAM alignment records processed.\n",
      "15200000 SAM alignment records processed.\n",
      "15300000 SAM alignment records processed.\n",
      "15400000 SAM alignment records processed.\n",
      "15500000 SAM alignment records processed.\n",
      "15600000 SAM alignment records processed.\n",
      "15700000 SAM alignment records processed.\n",
      "15800000 SAM alignment records processed.\n",
      "15900000 SAM alignment records processed.\n",
      "16000000 SAM alignment records processed.\n",
      "16100000 SAM alignment records processed.\n",
      "16200000 SAM alignment records processed.\n",
      "16300000 SAM alignment records processed.\n",
      "16400000 SAM alignment records processed.\n",
      "16500000 SAM alignment records processed.\n",
      "16600000 SAM alignment records processed.\n",
      "16700000 SAM alignment records processed.\n",
      "16800000 SAM alignment records processed.\n",
      "16900000 SAM alignment records processed.\n",
      "17000000 SAM alignment records processed.\n",
      "17100000 SAM alignment records processed.\n",
      "17200000 SAM alignment records processed.\n",
      "17300000 SAM alignment records processed.\n",
      "17400000 SAM alignment records processed.\n",
      "17500000 SAM alignment records processed.\n",
      "17600000 SAM alignment records processed.\n",
      "17700000 SAM alignment records processed.\n",
      "17800000 SAM alignment records processed.\n",
      "17900000 SAM alignment records processed.\n",
      "18000000 SAM alignment records processed.\n",
      "18100000 SAM alignment records processed.\n",
      "18200000 SAM alignment records processed.\n",
      "18300000 SAM alignment records processed.\n",
      "18400000 SAM alignment records processed.\n",
      "18500000 SAM alignment records processed.\n",
      "18600000 SAM alignment records processed.\n",
      "18700000 SAM alignment records processed.\n",
      "18800000 SAM alignment records processed.\n",
      "18900000 SAM alignment records processed.\n",
      "19000000 SAM alignment records processed.\n",
      "19100000 SAM alignment records processed.\n",
      "19200000 SAM alignment records processed.\n",
      "19300000 SAM alignment records processed.\n",
      "19400000 SAM alignment records processed.\n",
      "19500000 SAM alignment records processed.\n",
      "19600000 SAM alignment records processed.\n",
      "19700000 SAM alignment records processed.\n",
      "19800000 SAM alignment records processed.\n",
      "19900000 SAM alignment records processed.\n",
      "20000000 SAM alignment records processed.\n",
      "20100000 SAM alignment records processed.\n",
      "20200000 SAM alignment records processed.\n",
      "20300000 SAM alignment records processed.\n",
      "20400000 SAM alignment records processed.\n",
      "20500000 SAM alignment records processed.\n",
      "20600000 SAM alignment records processed.\n",
      "20700000 SAM alignment records processed.\n",
      "20800000 SAM alignment records processed.\n",
      "20900000 SAM alignment records processed.\n",
      "21000000 SAM alignment records processed.\n",
      "21100000 SAM alignment records processed.\n",
      "21159606 SAM alignments  processed.\n",
      "htseq-count --format=sam --stranded=no SRR3414631.uniq.sam  >   390,56s user 3,35s system 100% cpu 6:33,54 total\n",
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1872052 GFF lines processed.\n",
      "100000 SAM alignment records processed.\n",
      "200000 SAM alignment records processed.\n",
      "300000 SAM alignment records processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 SAM alignment records processed.\n",
      "500000 SAM alignment records processed.\n",
      "600000 SAM alignment records processed.\n",
      "700000 SAM alignment records processed.\n",
      "800000 SAM alignment records processed.\n",
      "900000 SAM alignment records processed.\n",
      "1000000 SAM alignment records processed.\n",
      "1100000 SAM alignment records processed.\n",
      "1200000 SAM alignment records processed.\n",
      "1300000 SAM alignment records processed.\n",
      "1400000 SAM alignment records processed.\n",
      "1500000 SAM alignment records processed.\n",
      "1600000 SAM alignment records processed.\n",
      "1700000 SAM alignment records processed.\n",
      "1800000 SAM alignment records processed.\n",
      "1900000 SAM alignment records processed.\n",
      "2000000 SAM alignment records processed.\n",
      "2100000 SAM alignment records processed.\n",
      "2200000 SAM alignment records processed.\n",
      "2300000 SAM alignment records processed.\n",
      "2400000 SAM alignment records processed.\n",
      "2500000 SAM alignment records processed.\n",
      "2600000 SAM alignment records processed.\n",
      "2700000 SAM alignment records processed.\n",
      "2800000 SAM alignment records processed.\n",
      "2900000 SAM alignment records processed.\n",
      "3000000 SAM alignment records processed.\n",
      "3100000 SAM alignment records processed.\n",
      "3200000 SAM alignment records processed.\n",
      "3300000 SAM alignment records processed.\n",
      "3400000 SAM alignment records processed.\n",
      "3500000 SAM alignment records processed.\n",
      "3600000 SAM alignment records processed.\n",
      "3700000 SAM alignment records processed.\n",
      "3800000 SAM alignment records processed.\n",
      "3900000 SAM alignment records processed.\n",
      "4000000 SAM alignment records processed.\n",
      "4100000 SAM alignment records processed.\n",
      "4200000 SAM alignment records processed.\n",
      "4300000 SAM alignment records processed.\n",
      "4400000 SAM alignment records processed.\n",
      "4500000 SAM alignment records processed.\n",
      "4600000 SAM alignment records processed.\n",
      "4700000 SAM alignment records processed.\n",
      "4800000 SAM alignment records processed.\n",
      "4900000 SAM alignment records processed.\n",
      "5000000 SAM alignment records processed.\n",
      "5100000 SAM alignment records processed.\n",
      "5200000 SAM alignment records processed.\n",
      "5300000 SAM alignment records processed.\n",
      "5400000 SAM alignment records processed.\n",
      "5500000 SAM alignment records processed.\n",
      "5600000 SAM alignment records processed.\n",
      "5700000 SAM alignment records processed.\n",
      "5800000 SAM alignment records processed.\n",
      "5900000 SAM alignment records processed.\n",
      "6000000 SAM alignment records processed.\n",
      "6100000 SAM alignment records processed.\n",
      "6200000 SAM alignment records processed.\n",
      "6300000 SAM alignment records processed.\n",
      "6400000 SAM alignment records processed.\n",
      "6500000 SAM alignment records processed.\n",
      "6600000 SAM alignment records processed.\n",
      "6700000 SAM alignment records processed.\n",
      "6800000 SAM alignment records processed.\n",
      "6900000 SAM alignment records processed.\n",
      "7000000 SAM alignment records processed.\n",
      "7100000 SAM alignment records processed.\n",
      "7200000 SAM alignment records processed.\n",
      "7300000 SAM alignment records processed.\n",
      "7400000 SAM alignment records processed.\n",
      "7500000 SAM alignment records processed.\n",
      "7600000 SAM alignment records processed.\n",
      "7700000 SAM alignment records processed.\n",
      "7800000 SAM alignment records processed.\n",
      "7900000 SAM alignment records processed.\n",
      "8000000 SAM alignment records processed.\n",
      "8100000 SAM alignment records processed.\n",
      "8200000 SAM alignment records processed.\n",
      "8300000 SAM alignment records processed.\n",
      "8400000 SAM alignment records processed.\n",
      "8500000 SAM alignment records processed.\n",
      "8600000 SAM alignment records processed.\n",
      "8700000 SAM alignment records processed.\n",
      "8800000 SAM alignment records processed.\n",
      "8900000 SAM alignment records processed.\n",
      "9000000 SAM alignment records processed.\n",
      "9100000 SAM alignment records processed.\n",
      "9200000 SAM alignment records processed.\n",
      "9300000 SAM alignment records processed.\n",
      "9400000 SAM alignment records processed.\n",
      "9500000 SAM alignment records processed.\n",
      "9600000 SAM alignment records processed.\n",
      "9700000 SAM alignment records processed.\n",
      "9800000 SAM alignment records processed.\n",
      "9900000 SAM alignment records processed.\n",
      "10000000 SAM alignment records processed.\n",
      "10100000 SAM alignment records processed.\n",
      "10200000 SAM alignment records processed.\n",
      "10300000 SAM alignment records processed.\n",
      "10400000 SAM alignment records processed.\n",
      "10500000 SAM alignment records processed.\n",
      "10600000 SAM alignment records processed.\n",
      "10700000 SAM alignment records processed.\n",
      "10800000 SAM alignment records processed.\n",
      "10900000 SAM alignment records processed.\n",
      "11000000 SAM alignment records processed.\n",
      "11100000 SAM alignment records processed.\n",
      "11200000 SAM alignment records processed.\n",
      "11300000 SAM alignment records processed.\n",
      "11400000 SAM alignment records processed.\n",
      "11500000 SAM alignment records processed.\n",
      "11600000 SAM alignment records processed.\n",
      "11700000 SAM alignment records processed.\n",
      "11800000 SAM alignment records processed.\n",
      "11900000 SAM alignment records processed.\n",
      "12000000 SAM alignment records processed.\n",
      "12100000 SAM alignment records processed.\n",
      "12200000 SAM alignment records processed.\n",
      "12300000 SAM alignment records processed.\n",
      "12400000 SAM alignment records processed.\n",
      "12500000 SAM alignment records processed.\n",
      "12600000 SAM alignment records processed.\n",
      "12700000 SAM alignment records processed.\n",
      "12800000 SAM alignment records processed.\n",
      "12900000 SAM alignment records processed.\n",
      "13000000 SAM alignment records processed.\n",
      "13100000 SAM alignment records processed.\n",
      "13200000 SAM alignment records processed.\n",
      "13300000 SAM alignment records processed.\n",
      "13400000 SAM alignment records processed.\n",
      "13500000 SAM alignment records processed.\n",
      "13600000 SAM alignment records processed.\n",
      "13700000 SAM alignment records processed.\n",
      "13800000 SAM alignment records processed.\n",
      "13900000 SAM alignment records processed.\n",
      "14000000 SAM alignment records processed.\n",
      "14100000 SAM alignment records processed.\n",
      "14200000 SAM alignment records processed.\n",
      "14300000 SAM alignment records processed.\n",
      "14400000 SAM alignment records processed.\n",
      "14500000 SAM alignment records processed.\n",
      "14600000 SAM alignment records processed.\n",
      "14700000 SAM alignment records processed.\n",
      "14800000 SAM alignment records processed.\n",
      "14900000 SAM alignment records processed.\n",
      "15000000 SAM alignment records processed.\n",
      "15100000 SAM alignment records processed.\n",
      "15200000 SAM alignment records processed.\n",
      "15300000 SAM alignment records processed.\n",
      "15400000 SAM alignment records processed.\n",
      "15500000 SAM alignment records processed.\n",
      "15600000 SAM alignment records processed.\n",
      "15700000 SAM alignment records processed.\n",
      "15800000 SAM alignment records processed.\n",
      "15900000 SAM alignment records processed.\n",
      "16000000 SAM alignment records processed.\n",
      "16100000 SAM alignment records processed.\n",
      "16200000 SAM alignment records processed.\n",
      "16300000 SAM alignment records processed.\n",
      "16400000 SAM alignment records processed.\n",
      "16500000 SAM alignment records processed.\n",
      "16600000 SAM alignment records processed.\n",
      "16700000 SAM alignment records processed.\n",
      "16800000 SAM alignment records processed.\n",
      "16900000 SAM alignment records processed.\n",
      "17000000 SAM alignment records processed.\n",
      "17100000 SAM alignment records processed.\n",
      "17200000 SAM alignment records processed.\n",
      "17300000 SAM alignment records processed.\n",
      "17400000 SAM alignment records processed.\n",
      "17500000 SAM alignment records processed.\n",
      "17600000 SAM alignment records processed.\n",
      "17700000 SAM alignment records processed.\n",
      "17800000 SAM alignment records processed.\n",
      "17900000 SAM alignment records processed.\n",
      "18000000 SAM alignment records processed.\n",
      "18100000 SAM alignment records processed.\n",
      "18200000 SAM alignment records processed.\n",
      "18300000 SAM alignment records processed.\n",
      "18400000 SAM alignment records processed.\n",
      "18500000 SAM alignment records processed.\n",
      "18600000 SAM alignment records processed.\n",
      "18637053 SAM alignments  processed.\n",
      "htseq-count --format=sam --stranded=no SRR3414635.uniq.sam  >   345,29s user 3,13s system 100% cpu 5:47,94 total\n",
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800000 GFF lines processed.\n",
      "1872052 GFF lines processed.\n",
      "100000 SAM alignment records processed.\n",
      "200000 SAM alignment records processed.\n",
      "300000 SAM alignment records processed.\n",
      "400000 SAM alignment records processed.\n",
      "500000 SAM alignment records processed.\n",
      "600000 SAM alignment records processed.\n",
      "700000 SAM alignment records processed.\n",
      "800000 SAM alignment records processed.\n",
      "900000 SAM alignment records processed.\n",
      "1000000 SAM alignment records processed.\n",
      "1100000 SAM alignment records processed.\n",
      "1200000 SAM alignment records processed.\n",
      "1300000 SAM alignment records processed.\n",
      "1400000 SAM alignment records processed.\n",
      "1500000 SAM alignment records processed.\n",
      "1600000 SAM alignment records processed.\n",
      "1700000 SAM alignment records processed.\n",
      "1800000 SAM alignment records processed.\n",
      "1900000 SAM alignment records processed.\n",
      "2000000 SAM alignment records processed.\n",
      "2100000 SAM alignment records processed.\n",
      "2200000 SAM alignment records processed.\n",
      "2300000 SAM alignment records processed.\n",
      "2400000 SAM alignment records processed.\n",
      "2500000 SAM alignment records processed.\n",
      "2600000 SAM alignment records processed.\n",
      "2700000 SAM alignment records processed.\n",
      "2800000 SAM alignment records processed.\n",
      "2900000 SAM alignment records processed.\n",
      "3000000 SAM alignment records processed.\n",
      "3100000 SAM alignment records processed.\n",
      "3200000 SAM alignment records processed.\n",
      "3300000 SAM alignment records processed.\n",
      "3400000 SAM alignment records processed.\n",
      "3500000 SAM alignment records processed.\n",
      "3600000 SAM alignment records processed.\n",
      "3700000 SAM alignment records processed.\n",
      "3800000 SAM alignment records processed.\n",
      "3900000 SAM alignment records processed.\n",
      "4000000 SAM alignment records processed.\n",
      "4100000 SAM alignment records processed.\n",
      "4200000 SAM alignment records processed.\n",
      "4300000 SAM alignment records processed.\n",
      "4400000 SAM alignment records processed.\n",
      "4500000 SAM alignment records processed.\n",
      "4600000 SAM alignment records processed.\n",
      "4700000 SAM alignment records processed.\n",
      "4800000 SAM alignment records processed.\n",
      "4900000 SAM alignment records processed.\n",
      "5000000 SAM alignment records processed.\n",
      "5100000 SAM alignment records processed.\n",
      "5200000 SAM alignment records processed.\n",
      "5300000 SAM alignment records processed.\n",
      "5400000 SAM alignment records processed.\n",
      "5500000 SAM alignment records processed.\n",
      "5600000 SAM alignment records processed.\n",
      "5700000 SAM alignment records processed.\n",
      "5800000 SAM alignment records processed.\n",
      "5900000 SAM alignment records processed.\n",
      "6000000 SAM alignment records processed.\n",
      "6100000 SAM alignment records processed.\n",
      "6200000 SAM alignment records processed.\n",
      "6300000 SAM alignment records processed.\n",
      "6400000 SAM alignment records processed.\n",
      "6500000 SAM alignment records processed.\n",
      "6600000 SAM alignment records processed.\n",
      "6700000 SAM alignment records processed.\n",
      "6800000 SAM alignment records processed.\n",
      "6900000 SAM alignment records processed.\n",
      "7000000 SAM alignment records processed.\n",
      "7100000 SAM alignment records processed.\n",
      "7200000 SAM alignment records processed.\n",
      "7300000 SAM alignment records processed.\n",
      "7400000 SAM alignment records processed.\n",
      "7500000 SAM alignment records processed.\n",
      "7600000 SAM alignment records processed.\n",
      "7700000 SAM alignment records processed.\n",
      "7800000 SAM alignment records processed.\n",
      "7900000 SAM alignment records processed.\n",
      "8000000 SAM alignment records processed.\n",
      "8100000 SAM alignment records processed.\n",
      "8200000 SAM alignment records processed.\n",
      "8300000 SAM alignment records processed.\n",
      "8400000 SAM alignment records processed.\n",
      "8500000 SAM alignment records processed.\n",
      "8600000 SAM alignment records processed.\n",
      "8700000 SAM alignment records processed.\n",
      "8800000 SAM alignment records processed.\n",
      "8900000 SAM alignment records processed.\n",
      "9000000 SAM alignment records processed.\n",
      "9100000 SAM alignment records processed.\n",
      "9200000 SAM alignment records processed.\n",
      "9300000 SAM alignment records processed.\n",
      "9400000 SAM alignment records processed.\n",
      "9500000 SAM alignment records processed.\n",
      "9600000 SAM alignment records processed.\n",
      "9700000 SAM alignment records processed.\n",
      "9800000 SAM alignment records processed.\n",
      "9900000 SAM alignment records processed.\n",
      "10000000 SAM alignment records processed.\n",
      "10100000 SAM alignment records processed.\n",
      "10200000 SAM alignment records processed.\n",
      "10300000 SAM alignment records processed.\n",
      "10400000 SAM alignment records processed.\n",
      "10500000 SAM alignment records processed.\n",
      "10600000 SAM alignment records processed.\n",
      "10700000 SAM alignment records processed.\n",
      "10800000 SAM alignment records processed.\n",
      "10900000 SAM alignment records processed.\n",
      "11000000 SAM alignment records processed.\n",
      "11100000 SAM alignment records processed.\n",
      "11200000 SAM alignment records processed.\n",
      "11300000 SAM alignment records processed.\n",
      "11400000 SAM alignment records processed.\n",
      "11500000 SAM alignment records processed.\n",
      "11600000 SAM alignment records processed.\n",
      "11700000 SAM alignment records processed.\n",
      "11800000 SAM alignment records processed.\n",
      "11900000 SAM alignment records processed.\n",
      "12000000 SAM alignment records processed.\n",
      "12100000 SAM alignment records processed.\n",
      "12200000 SAM alignment records processed.\n",
      "12300000 SAM alignment records processed.\n",
      "12400000 SAM alignment records processed.\n",
      "12500000 SAM alignment records processed.\n",
      "12600000 SAM alignment records processed.\n",
      "12700000 SAM alignment records processed.\n",
      "12800000 SAM alignment records processed.\n",
      "12900000 SAM alignment records processed.\n",
      "13000000 SAM alignment records processed.\n",
      "13100000 SAM alignment records processed.\n",
      "13200000 SAM alignment records processed.\n",
      "13300000 SAM alignment records processed.\n",
      "13400000 SAM alignment records processed.\n",
      "13500000 SAM alignment records processed.\n",
      "13600000 SAM alignment records processed.\n",
      "13700000 SAM alignment records processed.\n",
      "13800000 SAM alignment records processed.\n",
      "13900000 SAM alignment records processed.\n",
      "14000000 SAM alignment records processed.\n",
      "14100000 SAM alignment records processed.\n",
      "14200000 SAM alignment records processed.\n",
      "14300000 SAM alignment records processed.\n",
      "14400000 SAM alignment records processed.\n",
      "14500000 SAM alignment records processed.\n",
      "14600000 SAM alignment records processed.\n",
      "14700000 SAM alignment records processed.\n",
      "14800000 SAM alignment records processed.\n",
      "14900000 SAM alignment records processed.\n",
      "15000000 SAM alignment records processed.\n",
      "15100000 SAM alignment records processed.\n",
      "15200000 SAM alignment records processed.\n",
      "15300000 SAM alignment records processed.\n",
      "15400000 SAM alignment records processed.\n",
      "15500000 SAM alignment records processed.\n",
      "15600000 SAM alignment records processed.\n",
      "15700000 SAM alignment records processed.\n",
      "15800000 SAM alignment records processed.\n",
      "15900000 SAM alignment records processed.\n",
      "16000000 SAM alignment records processed.\n",
      "16100000 SAM alignment records processed.\n",
      "16200000 SAM alignment records processed.\n",
      "16300000 SAM alignment records processed.\n",
      "16400000 SAM alignment records processed.\n",
      "16500000 SAM alignment records processed.\n",
      "16600000 SAM alignment records processed.\n",
      "16700000 SAM alignment records processed.\n",
      "16800000 SAM alignment records processed.\n",
      "16900000 SAM alignment records processed.\n",
      "17000000 SAM alignment records processed.\n",
      "17100000 SAM alignment records processed.\n",
      "17200000 SAM alignment records processed.\n",
      "17300000 SAM alignment records processed.\n",
      "17400000 SAM alignment records processed.\n",
      "17500000 SAM alignment records processed.\n",
      "17600000 SAM alignment records processed.\n",
      "17700000 SAM alignment records processed.\n",
      "17800000 SAM alignment records processed.\n",
      "17900000 SAM alignment records processed.\n",
      "18000000 SAM alignment records processed.\n",
      "18032679 SAM alignments  processed.\n",
      "htseq-count --format=sam --stranded=no SRR3414636.uniq.sam  >   335,47s user 2,97s system 100% cpu 5:37,84 total\n",
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1872052 GFF lines processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 SAM alignment records processed.\n",
      "200000 SAM alignment records processed.\n",
      "300000 SAM alignment records processed.\n",
      "400000 SAM alignment records processed.\n",
      "500000 SAM alignment records processed.\n",
      "600000 SAM alignment records processed.\n",
      "700000 SAM alignment records processed.\n",
      "800000 SAM alignment records processed.\n",
      "900000 SAM alignment records processed.\n",
      "1000000 SAM alignment records processed.\n",
      "1100000 SAM alignment records processed.\n",
      "1200000 SAM alignment records processed.\n",
      "1300000 SAM alignment records processed.\n",
      "1400000 SAM alignment records processed.\n",
      "1500000 SAM alignment records processed.\n",
      "1600000 SAM alignment records processed.\n",
      "1700000 SAM alignment records processed.\n",
      "1800000 SAM alignment records processed.\n",
      "1900000 SAM alignment records processed.\n",
      "2000000 SAM alignment records processed.\n",
      "2100000 SAM alignment records processed.\n",
      "2200000 SAM alignment records processed.\n",
      "2300000 SAM alignment records processed.\n",
      "2400000 SAM alignment records processed.\n",
      "2500000 SAM alignment records processed.\n",
      "2600000 SAM alignment records processed.\n",
      "2700000 SAM alignment records processed.\n",
      "2800000 SAM alignment records processed.\n",
      "2900000 SAM alignment records processed.\n",
      "3000000 SAM alignment records processed.\n",
      "3100000 SAM alignment records processed.\n",
      "3200000 SAM alignment records processed.\n",
      "3300000 SAM alignment records processed.\n",
      "3400000 SAM alignment records processed.\n",
      "3500000 SAM alignment records processed.\n",
      "3600000 SAM alignment records processed.\n",
      "3700000 SAM alignment records processed.\n",
      "3800000 SAM alignment records processed.\n",
      "3900000 SAM alignment records processed.\n",
      "4000000 SAM alignment records processed.\n",
      "4100000 SAM alignment records processed.\n",
      "4200000 SAM alignment records processed.\n",
      "4300000 SAM alignment records processed.\n",
      "4400000 SAM alignment records processed.\n",
      "4500000 SAM alignment records processed.\n",
      "4600000 SAM alignment records processed.\n",
      "4700000 SAM alignment records processed.\n",
      "4800000 SAM alignment records processed.\n",
      "4900000 SAM alignment records processed.\n",
      "5000000 SAM alignment records processed.\n",
      "5100000 SAM alignment records processed.\n",
      "5200000 SAM alignment records processed.\n",
      "5300000 SAM alignment records processed.\n",
      "5400000 SAM alignment records processed.\n",
      "5500000 SAM alignment records processed.\n",
      "5600000 SAM alignment records processed.\n",
      "5700000 SAM alignment records processed.\n",
      "5800000 SAM alignment records processed.\n",
      "5900000 SAM alignment records processed.\n",
      "6000000 SAM alignment records processed.\n",
      "6100000 SAM alignment records processed.\n",
      "6200000 SAM alignment records processed.\n",
      "6300000 SAM alignment records processed.\n",
      "6400000 SAM alignment records processed.\n",
      "6500000 SAM alignment records processed.\n",
      "6600000 SAM alignment records processed.\n",
      "6700000 SAM alignment records processed.\n",
      "6800000 SAM alignment records processed.\n",
      "6900000 SAM alignment records processed.\n",
      "7000000 SAM alignment records processed.\n",
      "7100000 SAM alignment records processed.\n",
      "7200000 SAM alignment records processed.\n",
      "7300000 SAM alignment records processed.\n",
      "7400000 SAM alignment records processed.\n",
      "7500000 SAM alignment records processed.\n",
      "7600000 SAM alignment records processed.\n",
      "7700000 SAM alignment records processed.\n",
      "7800000 SAM alignment records processed.\n",
      "7900000 SAM alignment records processed.\n",
      "8000000 SAM alignment records processed.\n",
      "8100000 SAM alignment records processed.\n",
      "8200000 SAM alignment records processed.\n",
      "8300000 SAM alignment records processed.\n",
      "8400000 SAM alignment records processed.\n",
      "8500000 SAM alignment records processed.\n",
      "8600000 SAM alignment records processed.\n",
      "8700000 SAM alignment records processed.\n",
      "8800000 SAM alignment records processed.\n",
      "8900000 SAM alignment records processed.\n",
      "9000000 SAM alignment records processed.\n",
      "9100000 SAM alignment records processed.\n",
      "9200000 SAM alignment records processed.\n",
      "9300000 SAM alignment records processed.\n",
      "9400000 SAM alignment records processed.\n",
      "9500000 SAM alignment records processed.\n",
      "9600000 SAM alignment records processed.\n",
      "9700000 SAM alignment records processed.\n",
      "9800000 SAM alignment records processed.\n",
      "9900000 SAM alignment records processed.\n",
      "10000000 SAM alignment records processed.\n",
      "10100000 SAM alignment records processed.\n",
      "10200000 SAM alignment records processed.\n",
      "10300000 SAM alignment records processed.\n",
      "10400000 SAM alignment records processed.\n",
      "10500000 SAM alignment records processed.\n",
      "10600000 SAM alignment records processed.\n",
      "10700000 SAM alignment records processed.\n",
      "10800000 SAM alignment records processed.\n",
      "10900000 SAM alignment records processed.\n",
      "11000000 SAM alignment records processed.\n",
      "11100000 SAM alignment records processed.\n",
      "11200000 SAM alignment records processed.\n",
      "11300000 SAM alignment records processed.\n",
      "11400000 SAM alignment records processed.\n",
      "11500000 SAM alignment records processed.\n",
      "11600000 SAM alignment records processed.\n",
      "11700000 SAM alignment records processed.\n",
      "11800000 SAM alignment records processed.\n",
      "11900000 SAM alignment records processed.\n",
      "12000000 SAM alignment records processed.\n",
      "12100000 SAM alignment records processed.\n",
      "12200000 SAM alignment records processed.\n",
      "12300000 SAM alignment records processed.\n",
      "12400000 SAM alignment records processed.\n",
      "12500000 SAM alignment records processed.\n",
      "12600000 SAM alignment records processed.\n",
      "12700000 SAM alignment records processed.\n",
      "12800000 SAM alignment records processed.\n",
      "12900000 SAM alignment records processed.\n",
      "13000000 SAM alignment records processed.\n",
      "13100000 SAM alignment records processed.\n",
      "13200000 SAM alignment records processed.\n",
      "13300000 SAM alignment records processed.\n",
      "13400000 SAM alignment records processed.\n",
      "13500000 SAM alignment records processed.\n",
      "13600000 SAM alignment records processed.\n",
      "13700000 SAM alignment records processed.\n",
      "13800000 SAM alignment records processed.\n",
      "13900000 SAM alignment records processed.\n",
      "14000000 SAM alignment records processed.\n",
      "14100000 SAM alignment records processed.\n",
      "14200000 SAM alignment records processed.\n",
      "14300000 SAM alignment records processed.\n",
      "14400000 SAM alignment records processed.\n",
      "14500000 SAM alignment records processed.\n",
      "14600000 SAM alignment records processed.\n",
      "14700000 SAM alignment records processed.\n",
      "14800000 SAM alignment records processed.\n",
      "14900000 SAM alignment records processed.\n",
      "15000000 SAM alignment records processed.\n",
      "15100000 SAM alignment records processed.\n",
      "15200000 SAM alignment records processed.\n",
      "15300000 SAM alignment records processed.\n",
      "15400000 SAM alignment records processed.\n",
      "15500000 SAM alignment records processed.\n",
      "15600000 SAM alignment records processed.\n",
      "15700000 SAM alignment records processed.\n",
      "15800000 SAM alignment records processed.\n",
      "15900000 SAM alignment records processed.\n",
      "16000000 SAM alignment records processed.\n",
      "16100000 SAM alignment records processed.\n",
      "16200000 SAM alignment records processed.\n",
      "16300000 SAM alignment records processed.\n",
      "16400000 SAM alignment records processed.\n",
      "16500000 SAM alignment records processed.\n",
      "16600000 SAM alignment records processed.\n",
      "16700000 SAM alignment records processed.\n",
      "16800000 SAM alignment records processed.\n",
      "16900000 SAM alignment records processed.\n",
      "17000000 SAM alignment records processed.\n",
      "17100000 SAM alignment records processed.\n",
      "17200000 SAM alignment records processed.\n",
      "17300000 SAM alignment records processed.\n",
      "17400000 SAM alignment records processed.\n",
      "17500000 SAM alignment records processed.\n",
      "17600000 SAM alignment records processed.\n",
      "17700000 SAM alignment records processed.\n",
      "17800000 SAM alignment records processed.\n",
      "17900000 SAM alignment records processed.\n",
      "18000000 SAM alignment records processed.\n",
      "18043406 SAM alignments  processed.\n",
      "htseq-count --format=sam --stranded=no SRR3414637.uniq.sam  >   331,33s user 2,85s system 100% cpu 5:33,65 total\n"
     ]
    }
   ],
   "source": [
    "!time htseq-count --format=sam --stranded=no SRR3414629.uniq.sam  gencode.vM25.annotation.gtf > SRR3414629.counts\n",
    "!time htseq-count --format=sam --stranded=no SRR3414630.uniq.sam  gencode.vM25.annotation.gtf > SRR3414630.counts\n",
    "!time htseq-count --format=sam --stranded=no SRR3414631.uniq.sam  gencode.vM25.annotation.gtf > SRR3414631.counts\n",
    "!time htseq-count --format=sam --stranded=no SRR3414635.uniq.sam  gencode.vM25.annotation.gtf > SRR3414635.counts\n",
    "!time htseq-count --format=sam --stranded=no SRR3414636.uniq.sam  gencode.vM25.annotation.gtf > SRR3414636.counts\n",
    "!time htseq-count --format=sam --stranded=no SRR3414637.uniq.sam  gencode.vM25.annotation.gtf > SRR3414637.counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHTMa6RlA_m4"
   },
   "source": [
    "* Смотрим сколько чтений не удалось приписать ни одному гену:\n",
    "* `__no_feature 1332692` – столько чтений соответствует участкам генома, где не аннотировано ни одного экзона\n",
    "* `__ambiguous 735108` – столько чтений могут принадлежать разным генам\n",
    "* Более подробно про такие случаи можно посмотреть в описании HTSeq-count - https://htseq.readthedocs.io/en/release_0.11.1/count.html\n",
    "* Итого, общее число чтений, соответствующих хотя бы одному гену равно: `<uniq count>` - `__no_feature` - `__ambiguous`\n",
    "* Для каждого образца приводим эту статистику в отчете на Github\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[34m/\u001b[0m\u001b[32m/\u001b[0m\u001b[31m/\u001b[0m \u001b]8;id=28170;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🔍 \u001b[2m| v1.11\u001b[0m\n",
      "\n",
      "\u001b[34m|           multiqc\u001b[0m | Search path : /home/sasha/Documents/HSE/BioMinor/HW3\n",
      "\u001b[2K\u001b[34m|\u001b[0m         \u001b[34msearching\u001b[0m | \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m373/373\u001b[0m  /373\u001b[0m \u001b[2m./FastQC/Configuration/limits.txt\u001b[0mtml\u001b[0m\n",
      "\u001b[?25h\u001b[34m|             htseq\u001b[0m | Found 6 reports\n",
      "\u001b[34m|           bowtie2\u001b[0m | Found 6 reports\n",
      "\u001b[34m|            fastqc\u001b[0m | Found 6 reports\n",
      "\u001b[34m|           multiqc\u001b[0m | Compressing plot data\n",
      "\u001b[34m|           multiqc\u001b[0m | \u001b[33mPrevious MultiQC output found! Adjusting filenames..\u001b[0m\n",
      "\u001b[34m|           multiqc\u001b[0m | \u001b[33mUse -f or --force to overwrite existing reports instead\u001b[0m\n",
      "\u001b[34m|           multiqc\u001b[0m | Report      : multiqc_report_1.html\n",
      "\u001b[34m|           multiqc\u001b[0m | Data        : multiqc_data_1\n",
      "\u001b[34m|           multiqc\u001b[0m | MultiQC complete\n"
     ]
    }
   ],
   "source": [
    "!python3 -m multiqc ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvENnVBnisX1",
    "outputId": "72c4b7a5-e6cb-43ea-93d3-06a73a302e3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__no_feature\t1620359\r\n",
      "__ambiguous\t728893\r\n",
      "__too_low_aQual\t0\r\n",
      "__not_aligned\t0\r\n",
      "__alignment_not_unique\t0\r\n"
     ]
    }
   ],
   "source": [
    "!grep '^__' SRR3414629.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__no_feature\t1251763\r\n",
      "__ambiguous\t484967\r\n",
      "__too_low_aQual\t0\r\n",
      "__not_aligned\t0\r\n",
      "__alignment_not_unique\t0\r\n"
     ]
    }
   ],
   "source": [
    "!grep '^__' SRR3414630.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__no_feature\t1718354\r\n",
      "__ambiguous\t827751\r\n",
      "__too_low_aQual\t0\r\n",
      "__not_aligned\t0\r\n",
      "__alignment_not_unique\t0\r\n"
     ]
    }
   ],
   "source": [
    "!grep '^__' SRR3414631.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__no_feature\t1406679\r\n",
      "__ambiguous\t767361\r\n",
      "__too_low_aQual\t0\r\n",
      "__not_aligned\t0\r\n",
      "__alignment_not_unique\t0\r\n"
     ]
    }
   ],
   "source": [
    "!grep '^__' SRR3414635.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__no_feature\t1347210\r\n",
      "__ambiguous\t742802\r\n",
      "__too_low_aQual\t0\r\n",
      "__not_aligned\t0\r\n",
      "__alignment_not_unique\t0\r\n"
     ]
    }
   ],
   "source": [
    "!grep '^__' SRR3414636.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__no_feature\t1411488\r\n",
      "__ambiguous\t717538\r\n",
      "__too_low_aQual\t0\r\n",
      "__not_aligned\t0\r\n",
      "__alignment_not_unique\t0\r\n"
     ]
    }
   ],
   "source": [
    "!grep '^__' SRR3414637.counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQ-ryqO0BiDp"
   },
   "source": [
    "* Объединям все файлы .counts по генам в один общий файл `ALL.counts`.\n",
    "* В качестве заголовка для каждого образца указывать не его SRR id, а c1, c2, c3 для контрольных образцов и r1, r2, r3 для перепрограммированных образцов.\n",
    "* Загружаем полученный ALL.counts файл в Github репозиторий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geneID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000000001.4</th>\n",
       "      <td>3466</td>\n",
       "      <td>3532</td>\n",
       "      <td>4078</td>\n",
       "      <td>4507</td>\n",
       "      <td>3964</td>\n",
       "      <td>5757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000000003.15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000000028.15</th>\n",
       "      <td>152</td>\n",
       "      <td>137</td>\n",
       "      <td>152</td>\n",
       "      <td>348</td>\n",
       "      <td>275</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000000031.16</th>\n",
       "      <td>55721</td>\n",
       "      <td>48392</td>\n",
       "      <td>56187</td>\n",
       "      <td>64722</td>\n",
       "      <td>33333</td>\n",
       "      <td>65188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000000037.17</th>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000118655.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000118656.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000118657.1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000118658.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSMUSG00000118659.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55401 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          c1     c2     c3     r1     r2     r3\n",
       "geneID                                                         \n",
       "ENSMUSG00000000001.4    3466   3532   4078   4507   3964   5757\n",
       "ENSMUSG00000000003.15      0      0      0      0      0      0\n",
       "ENSMUSG00000000028.15    152    137    152    348    275    472\n",
       "ENSMUSG00000000031.16  55721  48392  56187  64722  33333  65188\n",
       "ENSMUSG00000000037.17     43     44     53     79     70     92\n",
       "...                      ...    ...    ...    ...    ...    ...\n",
       "ENSMUSG00000118655.1       0      0      0      0      1      1\n",
       "ENSMUSG00000118656.1       0      0      0      0      0      0\n",
       "ENSMUSG00000118657.1       0      1      0      2      0      4\n",
       "ENSMUSG00000118658.1       0      0      0      0      0      0\n",
       "ENSMUSG00000118659.1       0      0      0      0      0      0\n",
       "\n",
       "[55401 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "r1 = pd.read_csv(\"SRR3414629.counts\", squeeze=True, sep='\\t', index_col=0, names=['r1'])[:-5]\n",
    "r2 = pd.read_csv(\"SRR3414630.counts\", squeeze=True, sep='\\t', index_col=0, names=['r2'])[:-5]\n",
    "r3 = pd.read_csv(\"SRR3414631.counts\", squeeze=True, sep='\\t', index_col=0, names=['r3'])[:-5]\n",
    "c1 = pd.read_csv(\"SRR3414635.counts\", squeeze=True, sep='\\t', index_col=0, names=['c1'])[:-5]\n",
    "c2 = pd.read_csv(\"SRR3414636.counts\", squeeze=True, sep='\\t', index_col=0, names=['c2'])[:-5]\n",
    "c3 = pd.read_csv(\"SRR3414637.counts\", squeeze=True, sep='\\t', index_col=0, names=['c3'])[:-5]\n",
    "all_counts = pd.concat([c1, c2, c3, r1, r2, r3], axis=1)\n",
    "all_counts.index.rename('geneID', inplace=True)\n",
    "all_counts.to_csv(\"ALL.counts\", sep='\\t')\n",
    "all_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c1</th>\n",
       "      <td>SRR3414635</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2</th>\n",
       "      <td>SRR3414636</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c3</th>\n",
       "      <td>SRR3414637</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1</th>\n",
       "      <td>SRR3414629</td>\n",
       "      <td>reprogramming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>SRR3414630</td>\n",
       "      <td>reprogramming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r3</th>\n",
       "      <td>SRR3414631</td>\n",
       "      <td>reprogramming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id      condition\n",
       "sample                           \n",
       "c1      SRR3414635        control\n",
       "c2      SRR3414636        control\n",
       "c3      SRR3414637        control\n",
       "r1      SRR3414629  reprogramming\n",
       "r2      SRR3414630  reprogramming\n",
       "r3      SRR3414631  reprogramming"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_info = pd.DataFrame([['SRR3414635', 'control'], ['SRR3414636', 'control'], ['SRR3414637', 'control'], ['SRR3414629', 'reprogramming'], ['SRR3414630', 'reprogramming'], ['SRR3414631', 'reprogramming']], index=['c1', 'c2', 'c3', 'r1', 'r2', 'r3'], columns=['id', 'condition'])\n",
    "all_info.index.rename('sample', inplace=True)\n",
    "all_info.to_csv('ALL.info', sep='\\t')\n",
    "all_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>total reads</th>\n",
       "      <th>mapped reads</th>\n",
       "      <th>unique mapped reads</th>\n",
       "      <th>matches</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SRR3414629</th>\n",
       "      <td>reprogramming</td>\n",
       "      <td>21106089</td>\n",
       "      <td>20869194 (98.84%)</td>\n",
       "      <td>18573565 (88.00%)</td>\n",
       "      <td>16224313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR3414630</th>\n",
       "      <td>reprogramming</td>\n",
       "      <td>15244711</td>\n",
       "      <td>15076437 (98.90%)</td>\n",
       "      <td>13320505 (87.38%)</td>\n",
       "      <td>11583775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR3414631</th>\n",
       "      <td>reprogramming</td>\n",
       "      <td>24244069</td>\n",
       "      <td>23964375 (98.85%)</td>\n",
       "      <td>21159606 (87.28%)</td>\n",
       "      <td>18613501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR3414635</th>\n",
       "      <td>control</td>\n",
       "      <td>20956475</td>\n",
       "      <td>20714431 (98.85%)</td>\n",
       "      <td>18637053 (88.93%)</td>\n",
       "      <td>16463013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR3414636</th>\n",
       "      <td>control</td>\n",
       "      <td>20307147</td>\n",
       "      <td>20073596 (98.85%)</td>\n",
       "      <td>18032679 (88.80%)</td>\n",
       "      <td>15942667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR3414637</th>\n",
       "      <td>control</td>\n",
       "      <td>20385570</td>\n",
       "      <td>20148675 (98.86%)</td>\n",
       "      <td>18043406 (88.51%)</td>\n",
       "      <td>15914380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     type  total reads       mapped reads unique mapped reads  \\\n",
       "sample ID                                                                       \n",
       "SRR3414629  reprogramming     21106089  20869194 (98.84%)   18573565 (88.00%)   \n",
       "SRR3414630  reprogramming     15244711  15076437 (98.90%)   13320505 (87.38%)   \n",
       "SRR3414631  reprogramming     24244069  23964375 (98.85%)   21159606 (87.28%)   \n",
       "SRR3414635        control     20956475  20714431 (98.85%)   18637053 (88.93%)   \n",
       "SRR3414636        control     20307147  20073596 (98.85%)   18032679 (88.80%)   \n",
       "SRR3414637        control     20385570  20148675 (98.86%)   18043406 (88.51%)   \n",
       "\n",
       "             matches  \n",
       "sample ID             \n",
       "SRR3414629  16224313  \n",
       "SRR3414630  11583775  \n",
       "SRR3414631  18613501  \n",
       "SRR3414635  16463013  \n",
       "SRR3414636  15942667  \n",
       "SRR3414637  15914380  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([\n",
    "    ['reprogramming', 21106089, f'{21106089 - 236895} (98.84%)', '18573565 (88.00%)', 18573565 - 1620359 - 728893],\n",
    "    ['reprogramming', 15244711, f'{15244711 - 168274} (98.90%)', '13320505 (87.38%)', 13320505 - 1251763 - 484967],\n",
    "    ['reprogramming', 24244069, f'{24244069 - 279694} (98.85%)', '21159606 (87.28%)', 21159606 - 1718354 - 827751],\n",
    "    ['control', 20956475, f'{20956475 - 242044} (98.85%)', '18637053 (88.93%)', 18637053 - 1406679 - 767361],\n",
    "    ['control', 20307147, f'{20307147 - 233551} (98.85%)', '18032679 (88.80%)', 18032679 - 1347210 - 742802],\n",
    "    ['control', 20385570, f'{20385570 - 236895} (98.86%)', '18043406 (88.51%)', 18043406 - 1411488 - 717538],\n",
    "], index=pd.Series([\n",
    "    'SRR3414629',\n",
    "    'SRR3414630',\n",
    "    'SRR3414631',\n",
    "    'SRR3414635',\n",
    "    'SRR3414636',\n",
    "    'SRR3414637',\n",
    "], name='sample ID'), columns=['type', 'total reads', 'mapped reads', 'unique mapped reads', 'matches',])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of hse21_HW3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
